"""
AI Processor Module

This module handles the interaction with a local LLM API
compatible with OpenAI's API.
It processes text in chunks suitable for LLM context limits.
"""

import logging
import requests

# pylint: disable=logging-fstring-interpolation,missing-timeout,broad-exception-raised


class AIProcessor:
    """
    AI Processor for processing text using a local LLM API.

    Attributes:
        api_url (str): The URL of the local LLM API.
        chunk_size (int): The size of text chunks to process at a time.
    """

    def __init__(self, api_url: str, chunk_size: int = 5000):
        """
        Initializes the AIProcessor with the API URL and chunk size.

        Args:
            api_url (str): The URL of the local LLM API.
            chunk_size (int): The size of text chunks to process.
        """
        self.api_url = api_url
        self.chunk_size = chunk_size
        logging.info(
            f"""
            [ai_processor] Initialized AIProcessor with API URL {api_url} and chunk size {chunk_size}
            """
            )

    def process_text(self, text: str) -> str:
        """
        Processes the given text in chunks using the local LLM API.

        Args:
            text (str): The text to be processed.

        Returns:
            str: The processed text.

        Raises:
            Exception: If the API request fails.
        """
        chunks = [text[i:i + self.chunk_size]
                  for i in range(0, len(text), self.chunk_size)]
        processed_chunks = []

        prompt = """
        The following is the text extracted from a PDF or EPUB file. You are
        formatting the text to be suitable for text-to-speech conversion. Do
        not change the text itself, only the formatting. For example, you can
        remove unnecessary whitespace, remove page numbers, etc.
        """

        for chunk in chunks:
            logging.info(
                f"[ai_processor] Processing chunk of length {len(chunk)}")
            logging.debug(f"[ai_processor] Chunk: {chunk}")
            data = {
                "prompt": prompt + chunk,
                "max_tokens": self.chunk_size,
                "temperature": 0.1,
                "top_p": 0.9
            }
            response = requests.post(
                f"{self.api_url}/v1/completions",
                headers={"Content-Type": "application/json"},
                json=data
            )
            if response.status_code == 200:
                logging.info(
                    f"[ai_processor] API request successful for chunk length {len(chunk)}")
                processed_chunk = response.json()['choices'][0]['text']
                logging.debug(
                    f"[ai_processor] Processed chunk: {processed_chunk}")
                processed_chunks.append(processed_chunk)
                logging.info(
                    f"[ai_processor] Appended rocessed chunk of length {len(processed_chunk)}")
            else:
                raise Exception(
                    f"[ai_processor] API request failed with code {response.status_code}"
                )

        return ' '.join(processed_chunks)
